train_reader{
  advise_reader {
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00000-of-00010"
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00001-of-00010"
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00002-of-00010"
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00003-of-00010"
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00004-of-00010"
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00005-of-00010"
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00006-of-00010"
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00007-of-00010"
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00008-of-00010"
    interleave_cycle_length: 1
    is_training: true
    shuffle_buffer_size: 4000
    map_num_parallel_calls: 5
    prefetch_buffer_size: 8000
    batch_size: 128
    max_num_texts: 10
    cache: "MEMORY"
    knowledge_query_to_id_file: "sparql_query2id.txt"
    knowledge_id_to_comment_file: "sparql_id2comment.txt"
    knowledge_max_tokens_to_keep: 30
    knowledge_max_comments_per_image: 15
    knowledge_remove_query: false
  }
}
eval_reader{
  advise_reader {
    input_pattern: "/own_files/yekeren/GCN/wsod_kb18519_trainval.record-00009-of-00010"
    interleave_cycle_length: 1
    is_training: false
    shuffle_buffer_size: 1000
    map_num_parallel_calls: 5
    prefetch_buffer_size: 2000
    batch_size: 1
    max_num_texts: 10
    cache: "MEMORY"
    knowledge_query_to_id_file: "sparql_query2id.txt"
    knowledge_id_to_comment_file: "sparql_id2comment.txt"
    knowledge_max_tokens_to_keep: 30
    knowledge_max_comments_per_image: 15
    knowledge_remove_query: false
  }
}
model {
  [ReasoningModel.ext] {
    shared_dims: 50
    glove_path: '/own_files/yekeren/GCN/glove.6B.50d.txt'
    slgn_vocab_list_path: 'configs/slogan.vocab'
    slgn_kb_vocab_list_path: 'configs/slogan-kb2.vocab'
    stmt_vocab_list_path: 'configs/qa.vocab'
    train_word_embedding: true
    project_word_embedding: true
    graph_creator {
      hierarchical_graph_creator {
        edge_mlp_options {
          hidden_layers: 1
          hidden_units: 100
          dropout_keep_prob: 0.5
        }
        feature_indicator: ALL
        attention_type: CO_ATTENTION
        graph_connection_dropout_keep_prob: 1.0
      }
    }
    text_encoder {
      avg_pooling_encoder {
      }
    }
    triplet_margin: 0.2
    triplet_ap_use_avg: true
    hyperparams {
      op: FC
      activation: RELU
      regularizer {
        l2_regularizer {
          weight: 0
        }
      }
      initializer {
        truncated_normal_initializer {
          mean: 0.0
          stddev: 0.01
        }
      }
      batch_norm {
        decay: 0.999
        center: true
        scale: false
        epsilon: 0.001
      }
    }
  }
}
train_config {
  max_steps: 20000
  max_gradient_norm: 2.0
  learning_rate: 0.002
  learning_rate_decay {
    decay_steps: 4000
    decay_rate: 1.0
    staircase: false
  }
  optimizer {
    rmsprop {
      decay: 0.95
      momentum: 1e-8
    }
  }
  save_summary_steps: 500
  save_checkpoints_steps: 2000
  keep_checkpoint_max: 40
  log_step_count_steps: 50
}
eval_config {
  steps: 20000
  start_delay_secs: 100000
  throttle_secs: 30
}


